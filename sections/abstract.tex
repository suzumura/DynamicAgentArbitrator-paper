% Abstract
\begin{abstract}
Multi-agent LLM systems achieve strong task performance through ensemble reasoning, but incur prohibitive inference costs due to uniform deployment of expensive frontier models regardless of task difficulty. We introduce the \textbf{Dynamic Agent Arbitrator (DAA)}, a meta-learning framework that adaptively selects among heterogeneous LLM tiers based on estimated task complexity, achieving cost-efficient multi-agent orchestration with provable error mitigation guarantees.

DAA integrates four synergistic components: (1) neural task encoding via Sentence Transformers and GRU networks that compress reasoning traces into latent representations capturing complexity; (2) diversity-based error detection via Jensen-Shannon Divergence across model outputs, providing training-free error signals (Pearson $r = 0.385$ with ground-truth errors); (3) a PPO-trained meta-policy selecting among inference strategies; and (4) \textbf{Evidence-Aware Selective Escalation}, a three-way response classification distinguishing confident answers, hard unknowns, and soft uncertainties to minimize wasteful model escalation.

We evaluate DAA on four real-world benchmarks using Qwen2.5 models (1.5B--14B) served on H100 GPUs. Across PlanCraft (multi-step planning), WorkBench (office automation), FinanceBench (financial QA), and BrowseComp-Plus (evidence extraction), DAA achieves \textbf{equal or superior performance} to large-model baselines while reducing inference costs by \textbf{39.0\% on average} (range: 8--66\%). In head-to-head comparison with existing model routing methods---FrugalGPT, RouteLLM, and Cascade---DAA attains the highest cost-efficiency ratio (0.969 vs next-best 0.929) and is the only method to match or exceed baseline accuracy on \emph{every} benchmark. On PlanCraft, DAA's Best-of-Both-Models effect yields 70.0\% accuracy, exceeding both the 14B baseline (64.0\%) and 7B baseline (42.0\%), while operating at 16 percentage points lower cost than competing methods achieving the same accuracy. The selective escalation mechanism reduces wasteful expensive-model invocations by 79\%, and the overall cost-efficiency improves by \textbf{1.9$\times$} across benchmarks. Theoretical analysis establishes bounded error propagation under intervention and monotonic policy improvement guarantees.
\end{abstract}
